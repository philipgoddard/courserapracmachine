<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Courserapracmachine by philipgoddard</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Courserapracmachine</h1>
      <h2 class="project-tagline">coursework for practical machine learning. No copying please :)</h2>
      <a href="https://github.com/philipgoddard/courserapracmachine" class="btn">View on GitHub</a>
      <a href="https://github.com/philipgoddard/courserapracmachine/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/philipgoddard/courserapracmachine/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <p>&lt;!DOCTYPE html&gt;</p>

<p></p>

<p></p>

<p>

</p>

<p></p>Machine Learning



<p>
</p>







code{white-space: pre;}

<p></p>




  pre:not([class]) {
    background-color: white;
  }




<p></p>

<p></p>


.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}


<div>


<div id="header">
<h1>
<a id="machine-learning" class="anchor" href="#machine-learning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Machine Learning</h1>
</div>

<div id="introduction-data-splitting-and-data-cleansing">
<h2>
<a id="introduction-data-splitting-and-data-cleansing" class="anchor" href="#introduction-data-splitting-and-data-cleansing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction, Data Splitting and Data Cleansing</h2>
<p>This assignment is concerned with applying machine learning techniques to classify the manner in which excercise was performed. The raw data set has 160 columns, and the goal is to be able to predict the manner in which the excercise was performed. The variable ‘classe’ categorizes the manner into A,B,C,D and E.</p>
<p>A training and test set are provided, however the test set is to be used to validate our model, so the training set should be split into a training and test set. A 75:25 training:test split is used after setting the seed to ensure the method is reproducable. The splitting will allow cross validation of the final model.</p>
<pre><code>set.seed(1234)
inTrain = createDataPartition(data$classe, p = 3/4)[[1]]
training = data[ inTrain,]
testing = data[-inTrain,]</code></pre>
<p>Many columns contain predominantly NA’s. I chose to remove these, as imputing this many missing values will not provide good results. Further, the first seven columns contain labels, not predictors, so they should be removed. Additionally, I want to ensure that there are no colinear predictors or near zero variance predictors. This can be tested with nearZeroVar() and findCorrelation(), and it turns out that there are no predictors that should be removed for this reason.</p>
<pre><code>table(sapply(as.list(training), function(x){ sum(is.na(x)) }))</code></pre>
<pre><code>## 
##     0 14409 
##    60   100</code></pre>
<pre><code>training &lt;- training[ , colSums(is.na(training)) == 0 ]
#can also remove columns 1:7 as they are labels
training &lt;- select(training, -c(1:7))</code></pre>
<p>So overall, we are left with 52 predictors to determine the outcome ‘classe’.</p>
</div>

<div id="exploratory-data-analysis">
<h2>
<a id="exploratory-data-analysis" class="anchor" href="#exploratory-data-analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Exploratory Data Analysis</h2>
<p>The aim of the exploratory data analysis is to determine what type of model might be suitable.</p>
<p><img title alt width="672"></p>
<p>The sample plots demonstrate that many of the variables do not look normally distributed, so linear models might struggle without preprocessing. A PCA decomposition is shown below</p>
<pre><code>training.pca &lt;- prcomp(training[,-53], center = TRUE, scale. = TRUE)
g &lt;- ggbiplot(training.pca, obs.scale = 1, var.scale = 1, 
              groups = training$classe, ellipse = TRUE, 
              circle = TRUE)
g &lt;- g + scale_color_discrete(name = '')
g &lt;- g + theme(legend.direction = 'horizontal', 
               legend.position = 'top')
print(g)</code></pre>
<p><img title alt width="672"></p>
<p>This shows us that after the PCA, which we do to create a new set of variables that explains the most variance of the data set, when using all the variable, unique clusters do not form for each classe. This suggests that linear models may struggle without considerable effort preprocessing or carefully selecting and testing which features produce clear well seperated clusters. Therefore, a non-linear model will be applied.</p>
</div>

<div id="modelling-strategy">
<h2>
<a id="modelling-strategy" class="anchor" href="#modelling-strategy" aria-hidden="true"><span class="octicon octicon-link"></span></a>Modelling Strategy</h2>
<p>A random forest will be fitted to the training data. The model is well known for accuracy, but is prone to overfitting and can take a long time to fit. (In fact, the model took over an hour to fit to the training data set)</p>
<pre><code>fitRF &lt;- train(classe~., data=training, model='rf')</code></pre>
<p>The caret defaults were used; it would only make sense to start adjusting them upon cross validation of the model if it did not perform well. For a random forest, the default resampling is 25 bootstrap resamples.</p>
</div>

<div id="results">
<h2>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results</h2>
<p>From the fit, we can see the 20 most important predictors below (see ?randomForest for definition of importance).</p>
<p><img title alt width="672"></p>
<p>Time to cross validate on our testing set. Select the same columns in testing as we did for training, and then predict using our random forest fit. We can look at the confusion matrix to pull out some useful statistics about the result.</p>
<pre><code>keep &lt;- names(training)
testing &lt;- testing[, c(unlist(keep))]
predRF &lt;- predict(fitRF, newdata=testing)
testing$RFpred &lt;- predRF
confusionMatrix(table(predRF,testing$classe))</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##       
## predRF    A    B    C    D    E
##      A 1395    7    0    0    0
##      B    0  939    6    1    0
##      C    0    3  846    8    2
##      D    0    0    3  794    1
##      E    0    0    0    1  898
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9935          
##                  95% CI : (0.9908, 0.9955)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9917          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   0.9895   0.9895   0.9876   0.9967
## Specificity            0.9980   0.9982   0.9968   0.9990   0.9998
## Pos Pred Value         0.9950   0.9926   0.9849   0.9950   0.9989
## Neg Pred Value         1.0000   0.9975   0.9978   0.9976   0.9993
## Prevalence             0.2845   0.1935   0.1743   0.1639   0.1837
## Detection Rate         0.2845   0.1915   0.1725   0.1619   0.1831
## Detection Prevalence   0.2859   0.1929   0.1752   0.1627   0.1833
## Balanced Accuracy      0.9990   0.9938   0.9931   0.9933   0.9982</code></pre>
<p>The model is over 99% accurate on the test set, so I will stop here. In other words, I expect the out of sample error to be less than 1% on the validation set (so I should score 20/20!)</p>
</div>

<div id="conclusion">
<h2>
<a id="conclusion" class="anchor" href="#conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion</h2>
<p>A predictive model has been built to determine the manner in which an excercise is performed using 52 predictors, which are measurements from sensors attached to subjects. A random forest was chosen to build the model. The out of sample error is less than 1%. The model will now be applied to the validation set and submitted for grading.</p>
<pre><code>keep &lt;- names(training)
keep[53] &lt;- 'problem_id'
validation &lt;- validation[,c(unlist(keep))]
predRFV &lt;- predict(fitRF, newdata=validation)
predRFV</code></pre>
<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E</code></pre>
</div>

<p></p>
</div>







<p>
</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/philipgoddard/courserapracmachine">Courserapracmachine</a> is maintained by <a href="https://github.com/philipgoddard">philipgoddard</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>

